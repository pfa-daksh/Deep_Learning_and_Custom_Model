{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ccbca7",
   "metadata": {},
   "source": [
    "# Multiclass Image Classification using CNN and transfer learning on Weather images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcca6ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'img_to_array' from 'tensorflow.keras.utils' (C:\\Users\\Daksh Kapoor\\anaconda3\\lib\\site-packages\\tensorflow\\keras\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1f31ef47b362>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopyfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_to_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'img_to_array' from 'tensorflow.keras.utils' (C:\\Users\\Daksh Kapoor\\anaconda3\\lib\\site-packages\\tensorflow\\keras\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from shutil import copyfile\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from tensorflow.keras.utils import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc504337",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the paths\n",
    "data_dir_list = os.listdir(\"C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Multi-class Weather Dataset-group1\")\n",
    "print(data_dir_list)\n",
    "path, dirs, files = next(os.walk(\"C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Multi-class Weather Dataset-group1\"))\n",
    "file_count = len(files)\n",
    "# print(file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a24dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making new base directory, for creating training and test set\n",
    "original_dataset_dir = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Multi-class Weather Dataset-group1'\n",
    "base_dir = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/'\n",
    "os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two folders (train and test)\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "#Under train folder create four folders \n",
    "# (Cloud, Rain, Shine, Sunrise)\n",
    "\n",
    "train_cloud_dir = os.path.join(train_dir, 'cloudy')\n",
    "os.mkdir(train_cloud_dir)\n",
    "\n",
    "train_rainy_dir = os.path.join(train_dir, 'rainy')\n",
    "os.mkdir(train_rainy_dir)\n",
    "\n",
    "train_shine_dir = os.path.join(train_dir, 'shine')\n",
    "os.mkdir(train_shine_dir)\n",
    "\n",
    "train_sunrise_dir = os.path.join(train_dir, 'sunrise')\n",
    "os.mkdir(train_sunrise_dir)\n",
    "\n",
    "#Under test folder create four folders \n",
    "# (Cloud, Rain, Shine, Sunrise)\n",
    "\n",
    "validation_cloud_dir = os.path.join(validation_dir, 'cloudy')\n",
    "os.mkdir(validation_cloud_dir)\n",
    "\n",
    "validation_rainy_dir = os.path.join(validation_dir, 'rainy')\n",
    "os.mkdir(validation_rainy_dir)\n",
    "\n",
    "validation_shine_dir = os.path.join(validation_dir, 'shine')\n",
    "os.mkdir(validation_shine_dir)\n",
    "\n",
    "validation_sunrise_dir = os.path.join(validation_dir, 'sunrise')\n",
    "os.mkdir(validation_sunrise_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function has been created in order to copy the images from our original data file into the new\n",
    "# training and test folders we have created, we are giving 4 arguments to the function, source\n",
    "\n",
    "def split_data(SOURCE, TRAINING, TEST, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + '/' + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    test_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    test_set = shuffled_set[training_length:]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + '/' + filename\n",
    "        destination = TRAINING + '/' +filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in test_set:\n",
    "        this_file =  SOURCE + '/' + filename\n",
    "        destination = TEST + '/' + filename\n",
    "        copyfile(this_file, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77204450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below has been used 4 times, to create the training and testing data for the 4 seasons.\n",
    "\n",
    "CLOUDY_SOURCE_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Multi-class Weather Dataset-group1/Cloudy'\n",
    "TRAINING_CLOUDY_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/train/cloudy'\n",
    "TEST_CLOUDY_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/test/cloudy'\n",
    "\n",
    "RAINY_SOURCE_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Multi-class Weather Dataset-group1/Rain'\n",
    "TRAINING_RAINY_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/train/rainy'\n",
    "TEST_RAINY_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/test/rainy'\n",
    "\n",
    "SHINE_SOURCE_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Multi-class Weather Dataset-group1/Shine'\n",
    "TRAINING_SHINE_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/train/shine'\n",
    "TEST_SHINE_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/test/shine'\n",
    "\n",
    "SUNRISE_SOURCE_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Multi-class Weather Dataset-group1/Sunrise'\n",
    "TRAINING_SUNRISE_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/train/sunrise'\n",
    "TEST_SUNRISE_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/test/sunrise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6e32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048591e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372efed",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/train'\n",
    "TEST_DIR = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bb19e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed9e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e40835",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d690254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dffc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229f69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e4fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df7e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7f68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2552e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c75e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "split_size = .85\n",
    "\n",
    "split_data(CLOUDY_SOURCE_DIR, TRAINING_CLOUDY_DIR, TEST_CLOUDY_DIR, split_size)\n",
    "split_data(RAINY_SOURCE_DIR, TRAINING_RAINY_DIR, TEST_RAINY_DIR, split_size)\n",
    "split_data(SHINE_SOURCE_DIR, TRAINING_SHINE_DIR, TEST_SHINE_DIR, split_size)\n",
    "split_data(SUNRISE_SOURCE_DIR, TRAINING_SUNRISE_DIR, TEST_SUNRISE_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1563b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread\n",
    "import pathlib\n",
    "\n",
    "image_folder = ['cloudy','rainy', 'shine', 'sunrise']\n",
    "nimgs = {}\n",
    "for i in image_folder:\n",
    "    nimages = len(os.listdir('C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/train/'+i+'/'))\n",
    "    nimgs[i]=nimages\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.bar(range(len(nimgs)), list(nimgs.values()), align='center')\n",
    "plt.xticks(range(len(nimgs)), list(nimgs.keys()))\n",
    "plt.title('Distribution of different classes in Training Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df9d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['cloudy', 'rainy', 'shine', 'sunrise']:\n",
    "    print('Training {} images are: '.format(i)+str(len(os.listdir('C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/train/'+i+'/'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = ['cloudy','rainy', 'shine', 'sunrise']\n",
    "nimgs = {}\n",
    "for i in image_folder:\n",
    "    nimages = len(os.listdir('C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/test/'+i+'/'))\n",
    "    nimgs[i]=nimages\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.bar(range(len(nimgs)), list(nimgs.values()), align='center')\n",
    "plt.xticks(range(len(nimgs)), list(nimgs.keys()))\n",
    "plt.title('Distribution of different classes in Validation Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917cf572",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['cloudy', 'rainy', 'shine', 'sunrise']:\n",
    "    print('Test {} images are: '.format(i)+str(len(os.listdir('C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/test/'+i+'/'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25748d16",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8803667f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width=224; img_height=224 #We have to change the input and the output layers, as we are retaining the weights\n",
    "# of only hidden or convilutional layers, but since our input image size and number of output classes\n",
    "# in our case, change, we have to set them accordingly\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d04b9",
   "metadata": {},
   "source": [
    "# Using VGG16 and doing Data Augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10156d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1/255.0,\n",
    "                                   rotation_range=30,\n",
    "                                   zoom_range=0.4,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c163cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12919f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1/255.0)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              target_size=(img_height, img_width)\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg16.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87984692",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob('C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/train*')\n",
    "print(len(folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdac5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg16.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "model = Model(inputs=vgg16.input, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035dd902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "adam = optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f88603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give dataset path\n",
    "train_path = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/train'\n",
    "test_path = 'C:/Users/Daksh Kapoor/Desktop/DLAI_FInal_Project/Multi-class Weather Dataset-group1/Weather_image_data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f101b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 16,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98117295",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6dbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='mymodel.h5', \n",
    "                               verbose=2, save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model_history=model.fit_generator(\n",
    "  train_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=10,\n",
    "  steps_per_epoch=5,\n",
    "  validation_steps=32,\n",
    "    callbacks=callbacks ,verbose=2)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e180e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('CNN Model accuracy values')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b6b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=model_history.history['accuracy']\n",
    "val_acc=model_history.history['val_accuracy']\n",
    "loss=model_history.history['loss']\n",
    "val_loss=model_history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc))\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Testing Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682fb88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph for loss\n",
    "fig2 = plt.figure(figsize=(14,7))\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Testing Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6070441e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43339c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2697f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57138d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04418e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58424552",
   "metadata": {},
   "source": [
    "# Using VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd725f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55972a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg19.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b888f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg19.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "model1 = Model(inputs=vgg19.input, outputs=prediction)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de739733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "adam = optimizers.Adam()\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='mymodel.h5', \n",
    "                               verbose=2, save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model1_history=model1.fit_generator(\n",
    "  train_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=10,\n",
    "  steps_per_epoch=5,\n",
    "  validation_steps=32,\n",
    "    callbacks=callbacks ,verbose=2)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model1_history.history['accuracy'])\n",
    "plt.plot(model1_history.history['val_accuracy'])\n",
    "plt.title('CNN Model accuracy values')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6490d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "plt.plot(model1_history.history['loss'], label = 'train loss')\n",
    "plt.plot(model1_history.history['val_loss'], label = 'val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=model_history.history['accuracy']\n",
    "val_acc=model_history.history['val_accuracy']\n",
    "loss=model_history.history['loss']\n",
    "val_loss=model_history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc))\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Testing Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52181104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph for loss\n",
    "fig2 = plt.figure(figsize=(14,7))\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Testing Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b3a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ec69826",
   "metadata": {},
   "source": [
    "# Using Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0cff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res50 = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in res50.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(res50.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "model2 = Model(inputs=res50.input, outputs=prediction)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2189020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "adam = optimizers.Adam()\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c15c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='mymodel.h5', \n",
    "                               verbose=2, save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model2_history=model2.fit_generator(\n",
    "  train_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=10,\n",
    "  steps_per_epoch=5,\n",
    "  validation_steps=32,\n",
    "    callbacks=callbacks ,verbose=2)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=model2_history.history['accuracy']\n",
    "val_acc=model2_history.history['val_accuracy']\n",
    "loss=model2_history.history['loss']\n",
    "val_loss=model2_history.history['val_loss']\n",
    "\n",
    "\n",
    "#loss\n",
    "plt.plot(model2_history.history['loss'], label = 'train loss')\n",
    "plt.plot(model2_history.history['val_loss'], label = 'val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5256a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracies\n",
    "plt.plot(model2_history.history['accuracy'], label = 'train accuracy')\n",
    "plt.plot(model2_history.history['val_accuracy'], label = 'val accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca646f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1dc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3706ac5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6fc34f1",
   "metadata": {},
   "source": [
    "# Using Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fffaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = Xception(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ee565",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in xception.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd85838",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(xception.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "model3 = Model(inputs=xception.input, outputs=prediction)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc3d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "adam = optimizers.Adam()\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba318d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='mymodel.h5', \n",
    "                               verbose=2, save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model3_history=model2.fit_generator(\n",
    "  train_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=10,\n",
    "  steps_per_epoch=5,\n",
    "  validation_steps=32,\n",
    "    callbacks=callbacks ,verbose=2)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1962f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model3_history.history['accuracy'])\n",
    "plt.plot(model3_history.history['val_accuracy'])\n",
    "plt.title('CNN Model accuracy values')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef930f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "plt.plot(model3_history.history['loss'], label = 'train loss')\n",
    "plt.plot(model3_history.history['val_loss'], label = 'val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec02616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275450d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8fb129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11054eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af681e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
